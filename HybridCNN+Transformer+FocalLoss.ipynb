{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "0) IMPORT ทุกอย่างที่ต้องใช้"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import kagglehub   # ใช้โหลด dataset จาก Kaggle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ใช้ GPU ถ้ามี ไม่มีก็ใช้ CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Load Dataset (Kaggle BUSI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# โหลด dataset\n",
        "dpath = kagglehub.dataset_download(\"aryashah2k/breast-ultrasound-images-dataset\")\n",
        "print(\"Dataset path:\", dpath)\n",
        "\n",
        "folder = os.path.join(dpath, \"Dataset_BUSI_with_GT\")\n",
        "print(\"Classes:\", os.listdir(folder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Build DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = [\"benign\", \"malignant\", \"normal\"]\n",
        "data = []\n",
        "\n",
        "for idx, cls in enumerate(class_names):\n",
        "    cdir = os.path.join(folder, cls)\n",
        "    for fname in os.listdir(cdir):\n",
        "        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            data.append([os.path.join(cdir, fname), idx])\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"path\",\"label\"])\n",
        "print(\"Total images:\", len(df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Train/Val/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.15, stratify=df[\"label\"], random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1765, stratify=train_df[\"label\"], random_state=42)\n",
        "\n",
        "print(len(train_df), len(val_df), len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Dataset Class + CLAHE + Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n",
        "    transforms.Normalize([0.485]*3, [0.229]*3),\n",
        "])\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485]*3, [0.229]*3),\n",
        "])\n",
        "\n",
        "\n",
        "class BUSIDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.df.loc[idx, \"path\"]\n",
        "        label = self.df.loc[idx, \"label\"]\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = clahe.apply(img)\n",
        "        img = cv2.resize(img, (224,224))\n",
        "\n",
        "        img = np.stack([img, img, img], axis=-1)\n",
        "        img = img.astype(\"uint8\")\n",
        "\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return {\"image\": img, \"label\": torch.tensor(label).long()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = BUSIDataset(train_df, train_tf)\n",
        "val_ds   = BUSIDataset(val_df,   val_tf)\n",
        "test_ds  = BUSIDataset(test_df,  val_tf)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
        "dataset_sizes = {\"train\": len(train_ds), \"val\": len(val_ds)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        ce = nn.CrossEntropyLoss(reduction=\"none\")(logits, targets)\n",
        "        pt = torch.exp(-ce)\n",
        "        focal = ((1 - pt)**self.gamma) * ce\n",
        "        \n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.to(logits.device)[targets]\n",
        "            focal = alpha_t * focal\n",
        "\n",
        "        return focal.mean() if self.reduction==\"mean\" else focal.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compute class weight\n",
        "labels_np = train_df[\"label\"].values\n",
        "class_weights_np = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels_np),\n",
        "    y=labels_np\n",
        ")\n",
        "\n",
        "# boost malignant a bit\n",
        "class_weights_np[1] *= 1.2\n",
        "\n",
        "alpha_tensor = torch.tensor(class_weights_np, dtype=torch.float32).to(device)\n",
        "criterion = FocalLoss(alpha=alpha_tensor, gamma=2.0)\n",
        "print(\"Focal alpha:\", alpha_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Hybrid CNN + Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNTransformerHybrid(nn.Module):\n",
        "    def __init__(self, num_classes=3, backbone=\"resnet18\",\n",
        "                 num_layers=2, nhead=8, dim_feedforward=1024, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        if backbone==\"resnet18\":\n",
        "            resnet = models.resnet18(pretrained=True)\n",
        "            fdim = 512\n",
        "        else:\n",
        "            resnet = models.resnet50(pretrained=True)\n",
        "            fdim = 2048\n",
        "\n",
        "        self.conv1 = resnet.conv1\n",
        "        self.bn1   = resnet.bn1\n",
        "        self.relu  = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.layer4 = resnet.layer4\n",
        "\n",
        "        self.fdim = fdim\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1,fdim))\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1,50,fdim))\n",
        "\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=fdim,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(fdim),\n",
        "            nn.Linear(fdim, fdim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(fdim//2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x); x=self.layer2(x); x=self.layer3(x); x=self.layer4(x)\n",
        "\n",
        "        B,C,H,W = x.shape\n",
        "        x = x.view(B, C, H*W).transpose(1,2)\n",
        "\n",
        "        cls = self.cls_token.expand(B,-1,-1)\n",
        "        x = torch.cat([cls, x], dim=1)\n",
        "        x = x + self.pos_embed[:,:x.size(1)]\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        return self.head(x[:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_hybrid = CNNTransformerHybrid(\n",
        "    num_classes=3,\n",
        "    backbone=\"resnet18\"\n",
        ").to(device)\n",
        "\n",
        "print(model_hybrid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. Two-Phase Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 1: Freeze CNN backbone\n",
        "for name, param in model_hybrid.named_parameters():\n",
        "    if name.startswith((\"conv1\",\"bn1\",\"layer1\",\"layer2\",\"layer3\",\"layer4\")):\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "optimizer1 = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_hybrid.parameters()),\n",
        "    lr=1e-3\n",
        ")\n",
        "\n",
        "# Training loop function\n",
        "def train_model(model, criterion, optimizer, dataloaders, sizes,\n",
        "                num_epochs=10, scheduler=None, phase_name=\"Phase\"):\n",
        "\n",
        "    best_w = None\n",
        "    best_loss = 1e9\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n{phase_name} Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Train + Val\n",
        "        for phase in [\"train\",\"val\"]:\n",
        "            model.train() if phase==\"train\" else model.eval()\n",
        "\n",
        "            running_loss=0\n",
        "            running_corrects=0\n",
        "\n",
        "            for batch in dataloaders[phase]:\n",
        "                imgs = batch[\"image\"].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase==\"train\"):\n",
        "                    out = model(imgs)\n",
        "                    loss = criterion(out, labels)\n",
        "                    preds = out.argmax(1)\n",
        "\n",
        "                    if phase==\"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()*imgs.size(0)\n",
        "                running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            epoch_loss = running_loss/sizes[phase]\n",
        "            epoch_acc  = running_corrects.double()/sizes[phase]\n",
        "\n",
        "            print(f\"{phase} loss={epoch_loss:.4f} acc={epoch_acc:.4f}\")\n",
        "\n",
        "            if phase==\"val\" and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_w = model.state_dict()\n",
        "\n",
        "            if scheduler and phase==\"val\":\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "    model.load_state_dict(best_w)\n",
        "    return model\n",
        "\n",
        "# Train Phase 1\n",
        "model_hybrid = train_model(\n",
        "    model_hybrid, criterion, optimizer1,\n",
        "    dataloaders, dataset_sizes,\n",
        "    num_epochs=8,\n",
        "    phase_name=\"Hybrid Phase 1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Phase 2: Unfreeze layer4 + Transformer + Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, param in model_hybrid.named_parameters():\n",
        "    if name.startswith((\"layer4\",\"transformer\",\"head\",\"cls_token\",\"pos_embed\")):\n",
        "        param.requires_grad=True\n",
        "    else:\n",
        "        param.requires_grad=False\n",
        "\n",
        "optimizer2 = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_hybrid.parameters()),\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "scheduler2 = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer2, mode=\"min\", factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "model_hybrid = train_model(\n",
        "    model_hybrid, criterion, optimizer2,\n",
        "    dataloaders, dataset_sizes,\n",
        "    num_epochs=12,\n",
        "    scheduler=scheduler2,\n",
        "    phase_name=\"Hybrid Phase 2\"\n",
        ")\n",
        "\n",
        "best_model_hybrid = model_hybrid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "10. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model_hybrid.eval()\n",
        "probs=[]\n",
        "labels=[]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        x=batch[\"image\"].to(device)\n",
        "        y=batch[\"label\"].to(device)\n",
        "        o=best_model_hybrid(x)\n",
        "        p=torch.softmax(o,1)\n",
        "\n",
        "        probs.append(p.cpu().numpy())\n",
        "        labels.append(y.cpu().numpy())\n",
        "\n",
        "y_pred_proba=np.concatenate(probs)\n",
        "y_test=np.concatenate(labels)\n",
        "y_pred=np.argmax(y_pred_proba,1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Macro Recall:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "11. Threshold tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_threshold(y_pred_proba, y_true, th):\n",
        "    yp=[]\n",
        "    for p in y_pred_proba:\n",
        "        if p[1] >= th:\n",
        "            yp.append(1)\n",
        "        else:\n",
        "            yp.append(0 if p[0]>=p[2] else 2)\n",
        "\n",
        "    print(\"\\n=== T =\",th,\"===\")\n",
        "    print(\"Acc:\", accuracy_score(y_true, yp))\n",
        "    print(\"Macro F1:\", f1_score(y_true, yp, average=\"macro\"))\n",
        "    print(\"Macro Recall:\", recall_score(y_true, yp, average=\"macro\"))\n",
        "    print(confusion_matrix(y_true, yp))\n",
        "\n",
        "for th in [0.30,0.35,0.40,0.45,0.50]:\n",
        "    eval_threshold(y_pred_proba, y_test, th)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iTVBhzYanZ65",
        "DGOcjhJGnZ66",
        "G8nvJBlSnZ66",
        "llpL4cSynZ67",
        "U1ArlSy0xDuI",
        "KMkw3IehxV4m",
        "_nm3m3n7xz5M"
      ],
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1209633,
          "sourceId": 2021025,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
